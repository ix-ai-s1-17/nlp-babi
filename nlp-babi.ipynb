{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Default QA1 with 1000 samples\n",
    "#challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'\n",
    "# QA1 with 10,000 samples\n",
    "challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
    "# QA2 with 1000 samples\n",
    "#challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n",
    "# QA2 with 10,000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "tar = tarfile.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.text.strip() for x in nlp(sent) if x.text.strip()], [x.pos_ for x in nlp(sent) if x.text.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_stories(lines):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true,\n",
    "    only the sentences that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        # Get answer line\n",
    "        if '\\t' in line:\n",
    "            q, a, _ = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            data.append(([x for x in story if x], q, a))\n",
    "            story.append(('', '')) # End token\n",
    "        # Get story line\n",
    "        else:\n",
    "            story.append(tokenize(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stories(f):\n",
    "    '''Given a file name, read the file, retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines())\n",
    "    def dual_flatten(data):\n",
    "        words, pos = [], []\n",
    "        for d in data:\n",
    "            words.extend(d[0])\n",
    "            pos.extend(d[1])\n",
    "        return words, pos\n",
    "    data = [(dual_flatten(story), q, answer) for story, q, answer in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_idx, pos_idx, story_maxlen, query_maxlen):\n",
    "    xs = []\n",
    "    xspos = []\n",
    "    xqs = []\n",
    "    xqspos = []\n",
    "    ys = []\n",
    "    for story, query, answer in data:\n",
    "        story, storypos = story\n",
    "        query, querypos = query\n",
    "        x = [word_idx[w] for w in story]\n",
    "        xpos = [pos_idx[w] for w in storypos]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        xqpos = [pos_idx[w] for w in querypos]\n",
    "        # let's not forget that index 0 is reserved\n",
    "        y = np.zeros(len(word_idx) + 1)\n",
    "        y[word_idx[answer]] = 1\n",
    "        xs.append(x)\n",
    "        xspos.append(xpos)\n",
    "        xqs.append(xq)\n",
    "        xqspos.append(xqpos)\n",
    "        ys.append(y)\n",
    "    return (\n",
    "        pad_sequences(xs, maxlen=story_maxlen), pad_sequences(xspos, maxlen=story_maxlen),\n",
    "        pad_sequences(xqs, maxlen=query_maxlen), pad_sequences(xqspos, maxlen=query_maxlen),\n",
    "        np.array(ys)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = get_stories(tar.extractfile(challenge.format('train')))\n",
    "test = get_stories(tar.extractfile(challenge.format('test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'John',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'hallway',\n",
       "   '.'],\n",
       "  ['PROPN',\n",
       "   'VERB',\n",
       "   'ADP',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'PUNCT',\n",
       "   'PROPN',\n",
       "   'VERB',\n",
       "   'ADP',\n",
       "   'DET',\n",
       "   'NOUN',\n",
       "   'PUNCT']),\n",
       " (['Where', 'is', 'Mary', '?'], ['ADV', 'VERB', 'PROPN', 'PUNCT']),\n",
       " 'bathroom')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(inputs, idx, use_answer):\n",
    "    vocab = set()\n",
    "    for story, q, answer in inputs:\n",
    "        vocab |= set(story[idx] + q[idx])\n",
    "        if use_answer:\n",
    "            vocab.add(answer)\n",
    "    return sorted(vocab)\n",
    "\n",
    "word_vocab = build_vocab(train + test, 0, True)\n",
    "pos_vocab = build_vocab(train + test, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reserve 0 for masking via pad_sequences\n",
    "word_vocab_size = len(word_vocab) + 1\n",
    "pos_vocab_size = len(pos_vocab) + 1\n",
    "\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(word_vocab))\n",
    "pos_idx = dict((c, i + 1) for i, c in enumerate(pos_vocab))\n",
    "\n",
    "story_maxlen = max(map(len, (x[0] for x, _, _ in train + test)))\n",
    "query_maxlen = max(map(len, (x[0] for _, x, _ in train + test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, xpos, xq, xqpos, y = vectorize_stories(train, word_idx, pos_idx, story_maxlen, query_maxlen)\n",
    "tx, txpos, txq, txqpos, ty = vectorize_stories(test, word_idx, pos_idx, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_vocab = ['.', '?', 'Daniel', 'John', 'Mary', 'Sandra', 'Where', 'back', 'bathroom', 'bedroom', 'garden', 'hallway', 'is', 'journeyed', 'kitchen', 'moved', 'office', 'the', 'to', 'travelled', 'went']\n",
      "pos_vocab = ['ADP', 'ADV', 'DET', 'NOUN', 'PROPN', 'PUNCT', 'VERB']\n",
      "x.shape = (10000, 68)\n",
      "xpos.shape = (10000, 68)\n",
      "xq.shape = (10000, 4)\n",
      "xqpos.shape = (10000, 4)\n",
      "y.shape = (10000, 22)\n",
      "story_maxlen, query_maxlen = 68, 4\n"
     ]
    }
   ],
   "source": [
    "print('word_vocab = {}'.format(word_vocab))\n",
    "print('pos_vocab = {}'.format(pos_vocab))\n",
    "print('x.shape = {}'.format(x.shape))\n",
    "print('xpos.shape = {}'.format(xpos.shape))\n",
    "print('xq.shape = {}'.format(xq.shape))\n",
    "print('xqpos.shape = {}'.format(xqpos.shape))\n",
    "print('y.shape = {}'.format(y.shape))\n",
    "print('story_maxlen, query_maxlen = {}, {}'.format(story_maxlen, query_maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 50, 100, 100\n"
     ]
    }
   ],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "POS_EMBED_HIDDEN_SIZE = 10\n",
    "SENT_HIDDEN_SIZE = 100\n",
    "QUERY_HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 35\n",
    "print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,\n",
    "                                                           EMBED_HIDDEN_SIZE,\n",
    "                                                           SENT_HIDDEN_SIZE,\n",
    "                                                           QUERY_HIDDEN_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "def one_hot_embedder(n, input_tensor):\n",
    "    U = np.eye(n)\n",
    "    U[0, 0] = 0\n",
    "    return layers.Embedding(n, n, weights=[U], trainable=False)(input_tensor)\n",
    "    \n",
    "\n",
    "sentence = layers.Input(shape=(story_maxlen,), dtype='int32')\n",
    "sentence_pos = layers.Input(shape=(story_maxlen,), dtype='int32')\n",
    "encoded_sentence = layers.Embedding(word_vocab_size, EMBED_HIDDEN_SIZE)(sentence)\n",
    "encoded_sentence_pos = one_hot_embedder(pos_vocab_size, sentence_pos)\n",
    "encoded_sentence = layers.Dropout(0.3)(encoded_sentence)\n",
    "\n",
    "question = layers.Input(shape=(query_maxlen,), dtype='int32')\n",
    "question_pos = layers.Input(shape=(query_maxlen,), dtype='int32')\n",
    "encoded_question = layers.Embedding(word_vocab_size, EMBED_HIDDEN_SIZE)(question)\n",
    "encoded_question_pos = one_hot_embedder(pos_vocab_size, question_pos)\n",
    "encoded_question = layers.Dropout(0.3)(encoded_question)\n",
    "merged_question = layers.concatenate([encoded_question, encoded_question_pos])\n",
    "encoded_question = RNN(QUERY_HIDDEN_SIZE)(merged_question)\n",
    "\n",
    "encoded_question = layers.RepeatVector(story_maxlen)(encoded_question)\n",
    "\n",
    "merged = layers.concatenate([encoded_question, encoded_sentence, encoded_sentence_pos])\n",
    "merged = RNN(SENT_HIDDEN_SIZE)(merged)\n",
    "merged = layers.Dropout(0.3)(merged)\n",
    "preds = layers.Dense(word_vocab_size, activation='softmax')(merged)\n",
    "\n",
    "model = Model([sentence, sentence_pos, question, question_pos], preds)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([x, xpos, xq, xqpos], y,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.05)\n",
    "loss, acc = model.evaluate([tx, txpos, txq, txqpos], ty,\n",
    "                           batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 10\n",
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/15\n",
      "9/9 [==============================] - 0s - loss: 3.0728 - acc: 0.0000e+00 - val_loss: 2.9533 - val_acc: 0.0000e+00\n",
      "Epoch 2/15\n",
      "9/9 [==============================] - 0s - loss: 2.8824 - acc: 0.5556 - val_loss: 2.7891 - val_acc: 0.0000e+00\n",
      "Epoch 3/15\n",
      "9/9 [==============================] - 0s - loss: 2.6290 - acc: 0.5556 - val_loss: 2.4550 - val_acc: 0.0000e+00\n",
      "Epoch 4/15\n",
      "9/9 [==============================] - 0s - loss: 1.9138 - acc: 0.5556 - val_loss: 2.5537 - val_acc: 0.0000e+00\n",
      "Epoch 5/15\n",
      "9/9 [==============================] - 0s - loss: 1.2987 - acc: 0.5556 - val_loss: 2.0064 - val_acc: 0.0000e+00\n",
      "Epoch 6/15\n",
      "9/9 [==============================] - 0s - loss: 1.1872 - acc: 0.5556 - val_loss: 1.6188 - val_acc: 0.0000e+00\n",
      "Epoch 7/15\n",
      "9/9 [==============================] - 0s - loss: 1.1686 - acc: 0.5556 - val_loss: 1.6902 - val_acc: 0.0000e+00\n",
      "Epoch 8/15\n",
      "9/9 [==============================] - 0s - loss: 1.2313 - acc: 0.5556 - val_loss: 1.6130 - val_acc: 0.0000e+00\n",
      "Epoch 9/15\n",
      "9/9 [==============================] - 0s - loss: 1.1235 - acc: 0.4444 - val_loss: 1.9274 - val_acc: 0.0000e+00\n",
      "Epoch 10/15\n",
      "9/9 [==============================] - 0s - loss: 1.1434 - acc: 0.5556 - val_loss: 1.7511 - val_acc: 0.0000e+00\n",
      "Epoch 11/15\n",
      "9/9 [==============================] - 0s - loss: 1.2636 - acc: 0.5556 - val_loss: 1.5213 - val_acc: 0.0000e+00\n",
      "Epoch 12/15\n",
      "9/9 [==============================] - 0s - loss: 1.1986 - acc: 0.5556 - val_loss: 1.6929 - val_acc: 0.0000e+00\n",
      "Epoch 13/15\n",
      "9/9 [==============================] - 0s - loss: 1.0357 - acc: 0.6667 - val_loss: 1.4723 - val_acc: 0.0000e+00\n",
      "Epoch 14/15\n",
      "9/9 [==============================] - 0s - loss: 1.0012 - acc: 0.6667 - val_loss: 1.7412 - val_acc: 0.0000e+00\n",
      "Epoch 15/15\n",
      "9/9 [==============================] - 0s - loss: 1.0979 - acc: 0.4444 - val_loss: 1.5986 - val_acc: 0.0000e+00\n",
      " 992/1000 [============================>.] - ETA: 0sTraining 100\n",
      "Train on 95 samples, validate on 5 samples\n",
      "Epoch 1/15\n",
      "95/95 [==============================] - 1s - loss: 2.9018 - acc: 0.2105 - val_loss: 2.9694 - val_acc: 0.2000\n",
      "Epoch 2/15\n",
      "95/95 [==============================] - 0s - loss: 2.3505 - acc: 0.2105 - val_loss: 2.9047 - val_acc: 0.0000e+00\n",
      "Epoch 3/15\n",
      "95/95 [==============================] - 0s - loss: 2.1077 - acc: 0.2000 - val_loss: 2.3322 - val_acc: 0.2000\n",
      "Epoch 4/15\n",
      "95/95 [==============================] - 0s - loss: 2.0023 - acc: 0.2316 - val_loss: 2.0863 - val_acc: 0.0000e+00\n",
      "Epoch 5/15\n",
      "95/95 [==============================] - 0s - loss: 1.9206 - acc: 0.2000 - val_loss: 2.0397 - val_acc: 0.0000e+00\n",
      "Epoch 6/15\n",
      "95/95 [==============================] - 1s - loss: 1.9183 - acc: 0.2737 - val_loss: 2.0349 - val_acc: 0.2000\n",
      "Epoch 7/15\n",
      "95/95 [==============================] - 0s - loss: 1.8756 - acc: 0.2105 - val_loss: 2.0263 - val_acc: 0.2000\n",
      "Epoch 8/15\n",
      "95/95 [==============================] - 0s - loss: 1.9047 - acc: 0.2211 - val_loss: 2.0288 - val_acc: 0.0000e+00\n",
      "Epoch 9/15\n",
      "95/95 [==============================] - 0s - loss: 1.9155 - acc: 0.1684 - val_loss: 2.0115 - val_acc: 0.2000\n",
      "Epoch 10/15\n",
      "95/95 [==============================] - 0s - loss: 1.8640 - acc: 0.1684 - val_loss: 2.0158 - val_acc: 0.0000e+00\n",
      "Epoch 11/15\n",
      "95/95 [==============================] - 0s - loss: 1.8898 - acc: 0.1158 - val_loss: 2.1206 - val_acc: 0.2000\n",
      "Epoch 12/15\n",
      "95/95 [==============================] - 0s - loss: 1.8793 - acc: 0.1263 - val_loss: 2.0107 - val_acc: 0.2000\n",
      "Epoch 13/15\n",
      "95/95 [==============================] - 0s - loss: 1.8117 - acc: 0.2316 - val_loss: 2.1363 - val_acc: 0.0000e+00\n",
      "Epoch 14/15\n",
      "95/95 [==============================] - 0s - loss: 1.8162 - acc: 0.2526 - val_loss: 1.9228 - val_acc: 0.4000\n",
      "Epoch 15/15\n",
      "95/95 [==============================] - 0s - loss: 1.9108 - acc: 0.1474 - val_loss: 2.1770 - val_acc: 0.2000\n",
      " 992/1000 [============================>.] - ETA: 0sTraining 1000\n",
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/15\n",
      "950/950 [==============================] - 6s - loss: 1.8416 - acc: 0.2095 - val_loss: 2.0513 - val_acc: 0.0800\n",
      "Epoch 2/15\n",
      "950/950 [==============================] - 5s - loss: 1.7569 - acc: 0.2432 - val_loss: 1.6084 - val_acc: 0.3200\n",
      "Epoch 3/15\n",
      "950/950 [==============================] - 6s - loss: 1.6744 - acc: 0.3011 - val_loss: 1.7891 - val_acc: 0.3200\n",
      "Epoch 4/15\n",
      "950/950 [==============================] - 5s - loss: 1.6154 - acc: 0.3337 - val_loss: 1.5751 - val_acc: 0.3800\n",
      "Epoch 5/15\n",
      "950/950 [==============================] - 6s - loss: 1.5462 - acc: 0.3768 - val_loss: 1.5355 - val_acc: 0.4800\n",
      "Epoch 6/15\n",
      "950/950 [==============================] - 7s - loss: 1.4773 - acc: 0.4316 - val_loss: 1.4626 - val_acc: 0.4600\n",
      "Epoch 7/15\n",
      "950/950 [==============================] - 8s - loss: 1.4277 - acc: 0.4453 - val_loss: 1.5593 - val_acc: 0.4200\n",
      "Epoch 8/15\n",
      "950/950 [==============================] - 9s - loss: 1.3973 - acc: 0.4979 - val_loss: 1.4318 - val_acc: 0.4200\n",
      "Epoch 9/15\n",
      "950/950 [==============================] - 9s - loss: 1.3489 - acc: 0.4863 - val_loss: 1.4304 - val_acc: 0.5200\n",
      "Epoch 10/15\n",
      "950/950 [==============================] - 7s - loss: 1.3086 - acc: 0.5042 - val_loss: 1.6148 - val_acc: 0.3800\n",
      "Epoch 11/15\n",
      "950/950 [==============================] - 6s - loss: 1.2672 - acc: 0.5284 - val_loss: 1.4070 - val_acc: 0.5000\n",
      "Epoch 12/15\n",
      "950/950 [==============================] - 6s - loss: 1.2537 - acc: 0.5074 - val_loss: 1.2804 - val_acc: 0.5000\n",
      "Epoch 13/15\n",
      "950/950 [==============================] - 6s - loss: 1.2061 - acc: 0.5474 - val_loss: 1.3598 - val_acc: 0.4800\n",
      "Epoch 14/15\n",
      "950/950 [==============================] - 6s - loss: 1.1796 - acc: 0.5726 - val_loss: 1.3754 - val_acc: 0.4600\n",
      "Epoch 15/15\n",
      "950/950 [==============================] - 6s - loss: 1.1617 - acc: 0.5653 - val_loss: 1.2844 - val_acc: 0.5200\n",
      "1000/1000 [==============================] - 2s     \n",
      "Training 3000\n",
      "Train on 2850 samples, validate on 150 samples\n",
      "Epoch 1/15\n",
      "2850/2850 [==============================] - 21s - loss: 1.2330 - acc: 0.5253 - val_loss: 1.3696 - val_acc: 0.4800\n",
      "Epoch 2/15\n",
      "2850/2850 [==============================] - 19s - loss: 1.1808 - acc: 0.5309 - val_loss: 1.4275 - val_acc: 0.4533\n",
      "Epoch 3/15\n",
      "2850/2850 [==============================] - 20s - loss: 1.1691 - acc: 0.5204 - val_loss: 1.3636 - val_acc: 0.4600\n",
      "Epoch 4/15\n",
      "2850/2850 [==============================] - 18s - loss: 1.1319 - acc: 0.5379 - val_loss: 1.2766 - val_acc: 0.5133\n",
      "Epoch 5/15\n",
      "2850/2850 [==============================] - 22s - loss: 1.1258 - acc: 0.5291 - val_loss: 1.2508 - val_acc: 0.4600\n",
      "Epoch 6/15\n",
      "2850/2850 [==============================] - 19s - loss: 1.0993 - acc: 0.5432 - val_loss: 1.2594 - val_acc: 0.4800\n",
      "Epoch 7/15\n",
      "2850/2850 [==============================] - 18s - loss: 1.1021 - acc: 0.5421 - val_loss: 1.2965 - val_acc: 0.5000\n",
      "Epoch 8/15\n",
      "2850/2850 [==============================] - 22s - loss: 1.0821 - acc: 0.5456 - val_loss: 1.2492 - val_acc: 0.4800\n",
      "Epoch 9/15\n",
      "2850/2850 [==============================] - 23s - loss: 1.0652 - acc: 0.5491 - val_loss: 1.2271 - val_acc: 0.4933\n",
      "Epoch 10/15\n",
      "2850/2850 [==============================] - 23s - loss: 1.0492 - acc: 0.5523 - val_loss: 1.2930 - val_acc: 0.4733\n",
      "Epoch 11/15\n",
      "2850/2850 [==============================] - 18s - loss: 1.0378 - acc: 0.5575 - val_loss: 1.3002 - val_acc: 0.4733\n",
      "Epoch 12/15\n",
      "2850/2850 [==============================] - 19s - loss: 1.0367 - acc: 0.5488 - val_loss: 1.2526 - val_acc: 0.4867\n",
      "Epoch 13/15\n",
      "2850/2850 [==============================] - 19s - loss: 1.0143 - acc: 0.5653 - val_loss: 1.2625 - val_acc: 0.4867\n",
      "Epoch 14/15\n",
      "2850/2850 [==============================] - 21s - loss: 1.0149 - acc: 0.5484 - val_loss: 1.2105 - val_acc: 0.4667\n",
      "Epoch 15/15\n",
      "2850/2850 [==============================] - 20s - loss: 1.0004 - acc: 0.5684 - val_loss: 1.2859 - val_acc: 0.4933\n",
      " 992/1000 [============================>.] - ETA: 0sTraining 10000\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "9500/9500 [==============================] - 65s - loss: 1.0876 - acc: 0.5211 - val_loss: 1.1218 - val_acc: 0.4920\n",
      "Epoch 2/15\n",
      "9500/9500 [==============================] - 64s - loss: 1.0608 - acc: 0.5283 - val_loss: 1.1132 - val_acc: 0.4980\n",
      "Epoch 3/15\n",
      "9500/9500 [==============================] - 67s - loss: 1.0485 - acc: 0.5223 - val_loss: 1.1033 - val_acc: 0.5020\n",
      "Epoch 4/15\n",
      "9500/9500 [==============================] - 121s - loss: 1.0363 - acc: 0.5272 - val_loss: 1.1093 - val_acc: 0.4960\n",
      "Epoch 5/15\n",
      "9500/9500 [==============================] - 104s - loss: 1.0209 - acc: 0.5348 - val_loss: 1.1102 - val_acc: 0.4960\n",
      "Epoch 6/15\n",
      "9500/9500 [==============================] - 88s - loss: 1.0161 - acc: 0.5368 - val_loss: 1.1163 - val_acc: 0.4920\n",
      "Epoch 7/15\n",
      "9500/9500 [==============================] - 63s - loss: 1.0021 - acc: 0.5487 - val_loss: 1.1262 - val_acc: 0.5060\n",
      "Epoch 8/15\n",
      "9500/9500 [==============================] - 82s - loss: 0.9889 - acc: 0.5584 - val_loss: 1.0991 - val_acc: 0.4880\n",
      "Epoch 9/15\n",
      "9500/9500 [==============================] - 102s - loss: 0.9697 - acc: 0.5575 - val_loss: 1.0950 - val_acc: 0.5160\n",
      "Epoch 10/15\n",
      "9500/9500 [==============================] - 95s - loss: 0.9378 - acc: 0.5841 - val_loss: 1.0415 - val_acc: 0.5380\n",
      "Epoch 11/15\n",
      "9500/9500 [==============================] - 97s - loss: 0.8513 - acc: 0.6324 - val_loss: 0.8689 - val_acc: 0.6320\n",
      "Epoch 12/15\n",
      "9500/9500 [==============================] - 95s - loss: 0.6006 - acc: 0.7640 - val_loss: 0.4624 - val_acc: 0.8360\n",
      "Epoch 13/15\n",
      "9500/9500 [==============================] - 90s - loss: 0.2314 - acc: 0.9238 - val_loss: 0.0610 - val_acc: 0.9880\n",
      "Epoch 14/15\n",
      "9500/9500 [==============================] - 92s - loss: 0.0235 - acc: 0.9946 - val_loss: 9.3103e-04 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "9500/9500 [==============================] - 96s - loss: 0.0040 - acc: 0.9994 - val_loss: 2.1537e-05 - val_acc: 1.0000\n",
      "1000/1000 [==============================] - 3s     \n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for n_ex in [10, 100, 1000, 3000, 10000]:\n",
    "    print(\"Training\", n_ex)\n",
    "    model = Model([sentence, sentence_pos, question, question_pos], preds)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit([x[:n_ex], xpos[:n_ex], xq[:n_ex], xqpos[:n_ex]], y[:n_ex],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=15,\n",
    "          validation_split=0.05)\n",
    "    _, acc = model.evaluate([tx, txpos, txq, txqpos], ty,\n",
    "                               batch_size=BATCH_SIZE)\n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAGTCAYAAADUe046AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff79303acc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[6, 6])\n",
    "plt.semilogx([10, 100, 1000, 3000, 10000], accs, linewidth=3)\n",
    "plt.xlabel('Number of training examples', size=18)\n",
    "plt.ylabel('Test accuracy', size=18)\n",
    "plt.title('Accuracy on Task 1', size=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
